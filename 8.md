


### 问题背景


这是出现在某送公司面试中的问题。自动超参数调优一直以来都是模型训练过程中重要的一步，因此，考察对其的理解也是面试中经常出现的题目。

---

![avatar](https://github.com/AITutorials/manuals/blob/master/img/EI_MC_qMC.png)

---

### 解题思路


#### 第一步: 找出核心知识点并解析

* 自动超参数调优的方法:
	* 随机搜索(Random Search)：无放回的随机从给定的参数范围内进行超参数选择。优点：在大量超参数调节情况下速度最快。缺点：效果无法保证，不能获得全局最优。
	* 网格搜索(Grid Search)：通过给定的参数可能值，遍历其所有的组合进行超参数选择。优点：少量超参数时效果表现出色。缺点：超参数组合成指数增长，导致调优过程缓慢，同样不能不能保证获得全局最优。
	* 贝叶斯优化(Bayesian Optimization)：假设每个超参数都服从高斯分布，根据起始的几个超参数点，使用贝叶斯估计，得到超参数在该点的均值和方差(即新的高斯分布)，之后会使用一个叫做acq function的函数(它是关于当前已知点均值和方差的函数，如：均值+N*方差)来根据当前分布的均值和方差选取下一组超参数，以此类推。
	* 超频优化(Hyperband)：首先从所有超参数组合中进行随机均匀采样，对所选的超参数组合进行验证，根据验证结果淘汰部分超参数的可能值，之后在此基础上继续随机均匀采样超参数组合(不再使用淘汰值)进行验证，直到结果满足要求或者唯一。随机均匀采样也可以用上述的贝叶斯优化来代替，这种结合的方法叫做BOHB(Bayesian Optimization Hyperband)。


* 实现自动超参数调优的工具:
	* 对于tensorflow框架训练的模型，我们使用keras Tuner工具来实现。当前只支持随机搜索和超频优化。
	* 对于pytorch框架训练的模型，我们使用ray tune工具来实现。支持上述所有的优化方法以及BOHB。


---


#### 第二步: 整合核心知识点形成答案


    首先，明确超参数调优过程本身并不是一个凸优化问题，因此也无法使用常规的优化方法找到一组最优解。
    因此，工程中常用的自动化超参数调优方法有：随机搜索，网格搜索以及贝叶斯优化
    随机搜索和网格搜索的逻辑相对简单，贝叶斯优化逻辑相对复杂，它假设每个超参数都服从高斯分布，根据起始的几个超参数点，计算其后验分布，得到超参数在该点的均值和方差(即新的高斯分布)，之后会使用一个叫做acq function的函数(它是关于当前已知点均值和方差的函数，如：均值+N*方差)来根据当前分布的均值和方差选取下一组超参数，以此类推。
    对于tensorflow框架训练的模型，我们使用keras Tuner工具来实现。
    对于pytorch框架使用ray tune工具来实现。
    在我们现有的项目中，使用贝叶斯优化对已有的超参数进行调优确实能够提升1.5%的验证准确率。

---



