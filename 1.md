


### 问题背景


这是出现在某聘公司笔试中的问题。可见该公司可能在某些业务中正在使用BERT模型，并希望通过该问题验证面试者对BERT模型的了解程度，以及是否能够清晰阐述该模型的训练过程。

---

![avatar](./img/bert1.png)

---

### 解题思路


#### 第一步: 找出核心知识点并解析

* BERT模型:
>	* BERT也称双向Transformer编码器，它是由Transformer为基本单元构成的双向网络结构。BERT模型的创新点在于开启了迁移学习的篇章，它能够提供Masked LM，Next Sentence Prediction以及Question Answering任务的预训练模型，以增强在有限数据集下fine-tuning这些任务的效果。 

---

* 一般模型的训练过程:
>	* 1，训练数据预处理
>	* 2，初始化模型参数
>	* 3，批次化数据载入模型
>	* 4，对损失函数进行优化计算损失与梯度
>	* 5，梯度在反向传播中更新模型参数
>	* 6，按照以上过程迭代所有数据获得模型参数

---

#### 第二步: 整合核心知识点形成答案

    1，BERT模型训练数据预处理，包括数值映射，截断补齐，以及为句子对添加标记等		
    2，初始化BERT模型参数，即初始化各个Transformer中的带参数层，一般按照均匀分布方式初始化		
    3，将数据使用迭代器批次化，以节约内存载入模型			
    4，对BERT的交叉熵损失函数进行优化获得每个批次的平均损失与梯度		
    5，使用梯度在反向传播算法中更新模型所有的层参数		
    6，按照以上过程迭代所有数据获得模型参数

---

<!--

### 问题拓展

* 简述LSTM/GRU模型的训练过程
* 说一说是如何微调BERT模型的


---

-->
